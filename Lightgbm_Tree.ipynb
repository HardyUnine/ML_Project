{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced0b305",
   "metadata": {},
   "source": [
    "This is a gradient boosting model, it builds many trees sequentially, each new tree fixing the errors of the previous ones.\n",
    "It takes the values of our variables for a given day and tells us if **that day** there is a short squeeze, which is fun to do but does not answer our question of prediction so yayyy, ill try to find a way to make this useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ea1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eeb90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to the GitHub folder (NOT raw, NOT the file, but the folder)\n",
    "api_url = \"https://api.github.com/repos/HardyUnine/ML_Project/contents/plan_b\"\n",
    "\n",
    "# Get list of files in the folder\n",
    "files = requests.get(api_url).json()\n",
    "\n",
    "# Extract only CSV file URLs\n",
    "csv_urls = [f[\"download_url\"] for f in files if f[\"name\"].endswith(\".csv\")]\n",
    "\n",
    "# Load all CSVs into one dataframe\n",
    "dfs = []\n",
    "for url in csv_urls:\n",
    "    data = pd.read_csv(url)\n",
    "    data[\"source_file\"] = url.split(\"/\")[-1].replace(\".csv\", \"\")  # optional tag\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "# df = pd.read_csv(\"nom_a_changer.csv\") # CHANGE CSV NAME HERE ZZ\n",
    "# df.head()\n",
    "\n",
    "# # Cant have white space between words when wanting to draw trees!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b0839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_SHARES</th>\n",
       "      <th>SIR</th>\n",
       "      <th>RSI</th>\n",
       "      <th>BF</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PUBLIC</th>\n",
       "      <th>PRICE_PER_SHARE</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500000000</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30000000</td>\n",
       "      <td>480000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000000</td>\n",
       "      <td>25</td>\n",
       "      <td>48</td>\n",
       "      <td>0.097</td>\n",
       "      <td>29500000</td>\n",
       "      <td>480000000</td>\n",
       "      <td>98.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000000</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>0.094</td>\n",
       "      <td>29000000</td>\n",
       "      <td>480000000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500000000</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "      <td>0.091</td>\n",
       "      <td>28500000</td>\n",
       "      <td>480000000</td>\n",
       "      <td>95.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500000000</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>0.088</td>\n",
       "      <td>28000000</td>\n",
       "      <td>480000000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOTAL_SHARES  SIR  RSI     BF       ADV     PUBLIC  PRICE_PER_SHARE  SS\n",
       "0     500000000   25   50  0.100  30000000  480000000            100.0   0\n",
       "1     500000000   25   48  0.097  29500000  480000000             98.5   0\n",
       "2     500000000   25   46  0.094  29000000  480000000             97.0   0\n",
       "3     500000000   25   44  0.091  28500000  480000000             95.5   0\n",
       "4     500000000   25   42  0.088  28000000  480000000             94.0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['DAY', 'TICKER', 'COMPANY_NAME', 'source_file'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6488e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TOTAL_SHARES  SIR  RSI     BF       ADV     PUBLIC  PRICE_PER_SHARE\n",
      "0     500000000   25   50  0.100  30000000  480000000            100.0\n",
      "1     500000000   25   48  0.097  29500000  480000000             98.5\n",
      "2     500000000   25   46  0.094  29000000  480000000             97.0\n",
      "3     500000000   25   44  0.091  28500000  480000000             95.5\n",
      "4     500000000   25   42  0.088  28000000  480000000             94.0\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: SS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data in dependent and independant variables\n",
    "X = df.drop(columns=[\"SS\"])\n",
    "\n",
    "print(X.head())\n",
    "\n",
    "y = df[\"SS\"].copy()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d0d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26071428571428573\n",
      "0.2619047619047619\n",
      "0.2571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(sum(y)/len(y)) # to check how many positives we have\n",
    "# sum of how many squeezes, divided by total \n",
    "# data will probably be inbalances (ex. 30% squeezes) so need to make sure that there is 30% in both the train and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y) # stratify = yes, we want same percetages everywjere\n",
    "\n",
    "print(sum(y_train)/len(y_train))\n",
    "print(sum(y_test)/len(y_test)) # check that they have the same percentages of squeezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dfd678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 100                   4\n",
      "Actual Positive                   3                  33\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",        # change to \"multiclass\" if >2 classes\n",
    "    \"metric\": \"binary_logloss\",   # or \"multi_logloss\"\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "# Train model\n",
    "clf_lgb = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    num_boost_round=1000,\n",
    "    #early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "# Predictions (rounded to 0/1 for binary classification)\n",
    "y_pred_prob = clf_lgb.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred) # confusion matrixes\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['Actual Negative', 'Actual Positive'],\n",
    "    columns=['Predicted Negative', 'Predicted Positive']\n",
    ")\n",
    "\n",
    "print(cm_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Env",
   "language": "python",
   "name": "my-course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
